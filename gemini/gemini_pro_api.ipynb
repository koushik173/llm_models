{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import textwrap\n",
    "import google.generativeai as genai\n",
    "from IPython.display import display\n",
    "from IPython.display import Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "genai.configure(api_key='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/gemini-pro\n",
      "models/gemini-pro-vision\n"
     ]
    }
   ],
   "source": [
    "for m in genai.list_models():\n",
    "  if 'generateContent' in m.supported_generation_methods:\n",
    "    print(m.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = genai.GenerativeModel('gemini-pro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 7.35 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "response = model.generate_content(\"what is langchain?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LangChain is a machine-learning-based language model developed by Google AI. It is a type of neural network model known as a transformer, which allows it to learn from large amounts of text data and generate text in a natural and coherent way. LangChain is unique in that it is able to translate languages without the need for explicitly labeled parallel data. This makes it particularly useful for translating languages that have limited or no parallel data available.\\n\\nLangChain was introduced in a research paper titled \"Scaling Autoregressive Models for Language Generation\" by Yonghui Wu, Mike Schuster, Zhifeng Chen, Quoc V. Le, Mohammad Norouzi, Wolfgang Macherey, Maxim Krikun, Yuan Cao, Qin Gao, Jeff Dean, and Noah Smith. The paper describes the architecture and training procedure of the LangChain model and presents results on a variety of language translation tasks.\\n\\nThe LangChain model is based on the Transformer architecture, which is a type of neural network model that was originally developed for machine translation. Transformer models are known for their ability to learn long-range dependencies in text, which makes them well-suited for tasks such as language translation and text generation.\\n\\nThe LangChain model is trained on a massive dataset of text in multiple languages. This data is used to train the model to predict the next word in a sequence of words, given the previous words in the sequence. The model is trained using a self-supervised learning objective, which means that it is trained to predict the next word in a sequence of words, even if the target word is not explicitly provided in the training data.\\n\\nOnce the LangChain model is trained, it can be used to translate languages by generating the translation of a source sentence one word at a time. The model is able to translate languages without the need for explicitly labeled parallel data, which makes it particularly useful for translating languages that have limited or no parallel data available.\\n\\nThe LangChain model has been shown to achieve state-of-the-art results on a variety of language translation tasks, including English-to-German, German-to-English, English-to-French, and French-to-English translation. The model has also been shown to generate high-quality text in a variety of languages, including English, German, French, and Chinese.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_markdown(text):\n",
    "  text = text.replace('â€¢', '  *')\n",
    "  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "> LangChain is a machine-learning-based language model developed by Google AI. It is a type of neural network model known as a transformer, which allows it to learn from large amounts of text data and generate text in a natural and coherent way. LangChain is unique in that it is able to translate languages without the need for explicitly labeled parallel data. This makes it particularly useful for translating languages that have limited or no parallel data available.\n",
       "> \n",
       "> LangChain was introduced in a research paper titled \"Scaling Autoregressive Models for Language Generation\" by Yonghui Wu, Mike Schuster, Zhifeng Chen, Quoc V. Le, Mohammad Norouzi, Wolfgang Macherey, Maxim Krikun, Yuan Cao, Qin Gao, Jeff Dean, and Noah Smith. The paper describes the architecture and training procedure of the LangChain model and presents results on a variety of language translation tasks.\n",
       "> \n",
       "> The LangChain model is based on the Transformer architecture, which is a type of neural network model that was originally developed for machine translation. Transformer models are known for their ability to learn long-range dependencies in text, which makes them well-suited for tasks such as language translation and text generation.\n",
       "> \n",
       "> The LangChain model is trained on a massive dataset of text in multiple languages. This data is used to train the model to predict the next word in a sequence of words, given the previous words in the sequence. The model is trained using a self-supervised learning objective, which means that it is trained to predict the next word in a sequence of words, even if the target word is not explicitly provided in the training data.\n",
       "> \n",
       "> Once the LangChain model is trained, it can be used to translate languages by generating the translation of a source sentence one word at a time. The model is able to translate languages without the need for explicitly labeled parallel data, which makes it particularly useful for translating languages that have limited or no parallel data available.\n",
       "> \n",
       "> The LangChain model has been shown to achieve state-of-the-art results on a variety of language translation tasks, including English-to-German, German-to-English, English-to-French, and French-to-English translation. The model has also been shown to generate high-quality text in a variety of languages, including English, German, French, and Chinese."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_markdown(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -o image.jpg https://t0.gstatic.com/licensed-image?q=tbn:ANd9GcQ_Kevbk21QBRy-PgB4kQpS79brbmmEG7m3VOTShAn4PecDU5H5UxrJxE3Dw1JiaG17V88QIol19-3TM2wCHw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL.Image\n",
    "\n",
    "img = PIL.Image.open('image.jpg')\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = genai.GenerativeModel('gemini-pro-vision')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = model.generate_content(img)\n",
    "\n",
    "to_markdown(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = model.generate_content([\"Write a short, engaging blog post based on this picture. It should include a description of the meal in the photo and talk about my journey meal prepping.\", img], stream=True)\n",
    "response.resolve()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = genai.embed_content(\n",
    "    model=\"models/embedding-001\",\n",
    "    content=\"What is the meaning of life?\",\n",
    "    task_type=\"retrieval_document\",\n",
    "    title=\"Embedding of single string\")\n",
    "\n",
    "# 1 input > 1 vector output\n",
    "print(str(result['embedding'])[:50], '... TRIMMED]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = genai.embed_content(\n",
    "    model=\"models/embedding-001\",\n",
    "    content=[\n",
    "      'What is the meaning of life?',\n",
    "      'How much wood would a woodchuck chuck?',\n",
    "      'How does the brain work?'],\n",
    "    task_type=\"retrieval_document\",\n",
    "    title=\"Embedding of list of strings\")\n",
    "\n",
    "# A list of inputs > A list of vectors output\n",
    "for v in result['embedding']:\n",
    "  print(str(v)[:50], '... TRIMMED ...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
